{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Import Packages & Data](#Import-Packages-&-Data)\n",
    "- [Preprocess Text](#Preprocess-Text)\n",
    "- [Train Test Split](#Train-Test-Split)\n",
    "- [Limitations](#Limitations)\n",
    "- [Conclusion & Recommendations](#Conclusion-&-Recommendations)\n",
    "- [Sources](#Sources) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in data\n",
    "data = pd.read_csv('./data/processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>int_reviewerID</th>\n",
       "      <th>int_asin</th>\n",
       "      <th>reviewText_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1D4G1SNUZWQOT</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>exactly what i needed</td>\n",
       "      <td>1705385300413037995</td>\n",
       "      <td>-2353527134216546931</td>\n",
       "      <td>['exactly', 'needed']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3DDWDH9PX2YX2</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>i agree with the other review the opening is t...</td>\n",
       "      <td>5561379548298860475</td>\n",
       "      <td>-2353527134216546931</td>\n",
       "      <td>['agree', 'review', 'opening', 'small', 'almos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2MWC41EW7XL15</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>love these i am going to order another pack to...</td>\n",
       "      <td>3310565570865106017</td>\n",
       "      <td>-2353527134216546931</td>\n",
       "      <td>['love', 'going', 'order', 'another', 'pack', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2UH2QQ275NV45</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>too tiny an opening</td>\n",
       "      <td>-5293977400703050919</td>\n",
       "      <td>-2353527134216546931</td>\n",
       "      <td>['tiny', 'opening']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A89F3LQADZBS5</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>okay</td>\n",
       "      <td>-5397713386084954674</td>\n",
       "      <td>-2353527134216546931</td>\n",
       "      <td>['okay']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  \\\n",
       "0  A1D4G1SNUZWQOT  7106116521   \n",
       "1  A3DDWDH9PX2YX2  7106116521   \n",
       "2  A2MWC41EW7XL15  7106116521   \n",
       "3  A2UH2QQ275NV45  7106116521   \n",
       "4   A89F3LQADZBS5  7106116521   \n",
       "\n",
       "                                          reviewText       int_reviewerID  \\\n",
       "0                              exactly what i needed  1705385300413037995   \n",
       "1  i agree with the other review the opening is t...  5561379548298860475   \n",
       "2  love these i am going to order another pack to...  3310565570865106017   \n",
       "3                                too tiny an opening -5293977400703050919   \n",
       "4                                               okay -5397713386084954674   \n",
       "\n",
       "              int_asin                               reviewText_processed  \n",
       "0 -2353527134216546931                              ['exactly', 'needed']  \n",
       "1 -2353527134216546931  ['agree', 'review', 'opening', 'small', 'almos...  \n",
       "2 -2353527134216546931  ['love', 'going', 'order', 'another', 'pack', ...  \n",
       "3 -2353527134216546931                                ['tiny', 'opening']  \n",
       "4 -2353527134216546931                                           ['okay']  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling .head\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID                0\n",
       "asin                      0\n",
       "reviewText              249\n",
       "int_reviewerID            0\n",
       "int_asin                  0\n",
       "reviewText_processed      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for nulls \n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping any columns with no ReviewText\n",
    "data.dropna(subset = ['reviewText'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a baseline K-means clustering model we will need to process the `reviewText` column with a TFIDF vectorizer to feed into the clustering algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdif = TfidfVectorizer()\n",
    "\n",
    "text_df = tfdif.fit_transform(data['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.DataFrame(text_df.toarray(), columns = tfdif.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(782165, 128626)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([data, df_text], axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = combined_df.drop(columns = ['reviewText', 'reviewerID', 'reviewText_processed'])\n",
    "X = features\n",
    "y = combined_df['asin']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size =.70, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few limitations we should consider when it come to this model. First, the model was trained specificially on the data from the Amazon Fashion dataset, it will not perform as well on any other product group on Amazon, you would need to re-train the model for each different product group, as the words and topics in the reviews will be different. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and Recommendations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using LDA modeling we were able to find the ideal number of topics to segement the data based on different topics represented in the reviews. Not all of these topics were clear indicators of types of customers though, there were topics that represent different categories of products but also topics that represented how customers felt about the products they'd purchased. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justifying recommendations using distantly-labeled reviews and fined-grained aspects\n",
    "Jianmo Ni, Jiacheng Li, Julian McAuley\n",
    "Empirical Methods in Natural Language Processing (EMNLP), 2019\n",
    "\n",
    "https://colab.research.google.com/drive/1Zv6MARGQcrBbLHyjPVVMZVnRWsRnVMpV#scrollTo=LgWrDtZ94w89\n",
    "\n",
    "https://stylecaster.com/amazon-fashion-the-drop-by-you-february-2020/ Bella Gerard \n",
    "\n",
    "https://www.latimes.com/entertainment-arts/business/story/2020-02-22/amazon-making-the-cut-reality-tv-heidi-klum-prime\n",
    "Wendy Lee, Feb 22 2020\n",
    "\n",
    "https://github.com/marcotav/unsupervised-learning/tree/master/topic-modeling\n",
    "\n",
    "https://books.google.com/books?id=i8-PDwAAQBAJ&pg=PA164&lpg=PA164&dq=using+nlp+data+and+also+customer+ids+for+clustering&source=bl&ots=J8auw-oehF&sig=ACfU3U3RKK_rHPXi0dH6bQ-le4A9BXSUFw&hl=en&ppis=_c&sa=X&ved=2ahUKEwjg7fLK0ojoAhUtj3IEHSorC7gQ6AEwCXoECA8QAQ#v=onepage&q&f=false\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0\n",
    "\n",
    "https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0\n",
    "\n",
    "https://towardsdatascience.com/unsupervised-nlp-topic-models-as-a-supervised-learning-input-cf8ee9e5cf28\n",
    "\n",
    "Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces, pages 63â€“70,\n",
    "Baltimore, Maryland, USA, June 27, 2014. c 2014 Association for Computational Linguistics https://nlp.stanford.edu/events/illvi2014/papers/sievert-illvi2014.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
